import os
import streamlit as st
import time
import asyncio
import base64
import tempfile
from dotenv import load_dotenv

load_dotenv()

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

from openai import AsyncOpenAI

from prompts.prompt import VOICE_LLM_PROMPT

# OpenAI API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

st.set_page_config(
    page_title="voice_chat",
    page_icon="ğŸ¤"
)
st.title("voice_chat (LLM + OpenAI TTS)")



# Streamlitìš© ì±„íŒ… íˆìŠ¤í† ë¦¬ ì„¤ì •
@st.cache_resource
def get_chat_history():
    return StreamlitChatMessageHistory(key="voice_chat_messages")

def get_session_history(session_id: str):
    return get_chat_history()



def parse_llm_response(response: str):
    """
    LLMì˜ ì‘ë‹µì—ì„œ '[ëŒ€ë‹µ]' ë¶€ë¶„ê³¼ '[í”„ë¡¬í”„íŠ¸]' ë¶€ë¶„ì„ ê°ê° ì¶”ì¶œ
    """
    import re
    # [ëŒ€ë‹µ] ... --- [í”„ë¡¬í”„íŠ¸] ... íŒ¨í„´ì„ íŒŒì‹±
    answer = ""
    voice_prompt = ""
    # íŒ¨í„´ì— ë§ê²Œ ì •ê·œì‹ ì¶”ì¶œ
    match = re.search(
        r"\[ëŒ€ë‹µ\]\s*(.*?)\s*-{3,}\s*\[í”„ë¡¬í”„íŠ¸\]\s*(.*)", response, re.DOTALL)
    if match:
        answer = match.group(1).strip()
        voice_prompt = match.group(2).strip()
    else:
        # í˜¹ì‹œ íŒ¨í„´ì´ ì•ˆ ë§ìœ¼ë©´ ì „ì²´ ì‘ë‹µì„ ëŒ€ë‹µìœ¼ë¡œ ì‚¬ìš©
        answer = response.strip()
        voice_prompt = ""
    return answer, voice_prompt


# OpenAI ì±—ë´‡ ì„¤ì • ------------------------------------------------------
def create_chatbot(model_name="gpt-3.5-turbo", temperature=0.7):
    prompt = ChatPromptTemplate.from_messages([
        ("system", VOICE_LLM_PROMPT),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model=model_name,
        temperature=temperature
    )
    chain = prompt | llm | StrOutputParser()
    with_message_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="history",
    )
    return with_message_history


# TTS (OpenAI gpt-4o-mini-tts) : ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (wav ì„ì‹œíŒŒì¼ ë°˜í™˜)
async def generate_tts_wav(text, voice="alloy", instructions=""):
    client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    tmp_pcm = tempfile.NamedTemporaryFile(delete=False, suffix=".pcm")
    tmp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    # 1. PCM ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ë° ì €ì¥
    async with client.audio.speech.with_streaming_response.create(
        model="gpt-4o-mini-tts",
        voice=voice,
        input=text,
        instructions=instructions,
        response_format="pcm",
    ) as response:
        with open(tmp_pcm.name, "wb") as f:
            async for chunk in response.iter_bytes():
                f.write(chunk)
    # 2. PCM â†’ WAV ë³€í™˜ (16kHz, 1ch, 16bit)
    import wave
    with open(tmp_pcm.name, "rb") as pcmfile:
        pcmdata = pcmfile.read()
    with wave.open(tmp_wav.name, "wb") as wavfile:
        wavfile.setnchannels(1)
        wavfile.setsampwidth(2)  # 16bit PCM = 2 bytes
        wavfile.setframerate(24000)  # OpenAI PCMì€ 24kHz
        wavfile.writeframes(pcmdata)
    return tmp_wav.name

# -------------------------------------
# Streamlit ì¸í„°í˜ì´ìŠ¤
# -------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    model_name = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        ["gpt-4.1-nano", "gpt-4.1-mini", "gpt-4o-mini"],
        index=0
    )
    temperature = st.slider(
        "Temperature (ì°½ì˜ì„±)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1
    )
    
    # ìŒì„± ìºë¦­í„° ì„¤ì •
    st.subheader("ğŸ”Š ìŒì„± ìºë¦­í„° ì„¤ì •")
    voice_style = st.radio(
        "ìŒì„± ìŠ¤íƒ€ì¼",
        ["alloy", "ash", "ballad", "coral", "echo", "fable", "onyx", "nova", "sage", "shimmer", "verse"],
        index=0
    )
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        get_chat_history().clear()
        st.rerun()


    st.markdown("---")
    st.markdown("ğŸ’¡ **ê³„ì† ê°™ì€ ê°ì •ì˜ ëª©ì†Œë¦¬ê°€ ì•„ë‹ˆë¼ ìƒí™©ë³„ë¡œ ê°ì •ì´ ì„ì¸ í†¤ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤.**")
    st.markdown("ğŸ”Š **í™”ë‚œ ê°ì •ì¼ë•Œ ì–´ë–¤ ë§íˆ¬ëƒê³  ë¬¼ì–´ë³´ì„¸ìš”.**")

# -------------------------------------

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
msgs = get_chat_history()

# í™˜ì˜ ë©”ì‹œì§€ (ìµœì´ˆ ì ‘ì† ì‹œ)
if len(msgs.messages) == 0:
    with st.chat_message("assistant"):
        welcome_msg = "ë˜ ë³´ë„¤? ë˜ ë´ì„œ ê¸°ë» ğŸ˜Š"
        st.markdown(welcome_msg)

# ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— í‘œì‹œ - íˆìŠ¤í† ë¦¬ ì¶œë ¥
for message in msgs.messages:
    with st.chat_message(message.type):
        st.markdown(message.content)

chatbot = create_chatbot(
    model_name=model_name, 
    temperature=temperature
    )


# ------------------------------------------------------------------------------------------


# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # 1. LLM ë‹µë³€ ìƒì„±
            response = chatbot.invoke(
                {"input": user_input},
                config={"configurable": {"session_id": "default"}}
            )
            
            # 2. ì‘ë‹µ íŒŒì‹±: answer, voice_promptë¡œ ë¶„ë¦¬
            answer, voice_prompt = parse_llm_response(response)
            
            # íƒ€ì´í•‘ íš¨ê³¼
            displayed_response = ""
            for word in answer.split():
                displayed_response += word + " "
                time.sleep(0.05)
                message_placeholder.markdown(displayed_response + "â–Œ")
            # ìµœì¢… ë‹µë³€
            message_placeholder.markdown(answer)

            # 3. OpenAI TTSë¡œ ìŒì„± ë³€í™˜ ë° ì¬ìƒ
            st.info("AI ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë“£ëŠ” ì¤‘...")
            if not voice_prompt:
                voice_prompt = "You are a kind AI love partner." # Fallback prompt
            wav_path = asyncio.run(generate_tts_wav(answer, voice=voice_style, instructions=voice_prompt))
            audio_file = open(wav_path, 'rb')
            audio_bytes = audio_file.read()
            st.audio(audio_bytes, format="audio/wav")
            audio_file.close()
            os.remove(wav_path)
            
            # base64 ì¸ì½”ë”©
            audio_base64 = base64.b64encode(audio_bytes).decode()
            audio_html = f"""
            <audio autoplay>
                <source src="data:audio/wav;base64,{audio_base64}" type="audio/wav">
                ë¸Œë¼ìš°ì €ê°€ audio íƒœê·¸ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            </audio>
            """
            st.markdown(audio_html, unsafe_allow_html=True)
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")
            message_placeholder.markdown("â— ìŒì„± í•©ì„± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ì•ˆë‚´
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <small>
            ì±—ë´‡ì´ ëŒ€ë‹µí•˜ë©´, AIê°€ ì§ì ‘ ìŒì„±ìœ¼ë¡œ ì½ì–´ì¤ë‹ˆë‹¤.<br>
            <b>ìŒì„±ì´ ìë™ ì¬ìƒë˜ì§€ ì•Šìœ¼ë©´, ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ ì¬ìƒì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.</b>
        </small>
    </div>
    """,
    unsafe_allow_html=True
)
