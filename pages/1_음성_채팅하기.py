import os
import streamlit as st
import time
import asyncio
import base64
import tempfile
from dotenv import load_dotenv

load_dotenv()

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

from openai import AsyncOpenAI

# OpenAI API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

st.set_page_config(
    page_title="ìŒì„± ì±„íŒ…í•˜ê¸°",
    page_icon="ğŸ¤"
)
st.title("ìŒì„± ì±„íŒ…í•˜ê¸° (LLM + OpenAI TTS)")

# LLM í”„ë¡¬í”„íŠ¸(ì„±ê²© ìŠ¤íƒ€ì¼)
INSTRUCTIONS = """
Personality/affect: a high-energy cheerleader helping with administrative tasks

Voice: Enthusiastic, and bubbly, with an uplifting and motivational quality.

Tone: Encouraging and playful, making even simple tasks feel exciting and fun.

Dialect: Casual and upbeat, using informal phrasing and pep talk-style expressions.

Pronunciation: Crisp and lively, with exaggerated emphasis on positive words to keep the energy high.

Features: Uses motivational phrases, cheerful exclamations, and an energetic rhythm to create a sense of excitement and engagement.
"""

# Streamlitìš© ì±„íŒ… íˆìŠ¤í† ë¦¬ ì„¤ì •
@st.cache_resource
def get_chat_history():
    return StreamlitChatMessageHistory(key="voice_chat_messages")

def get_session_history(session_id: str):
    return get_chat_history()

# LLM ì±—ë´‡ ìƒì„±
def create_chatbot(model_name="gpt-3.5-turbo", temperature=0.7):
    prompt = ChatPromptTemplate.from_messages([
        ("system", INSTRUCTIONS),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model=model_name,
        temperature=temperature
    )
    chain = prompt | llm | StrOutputParser()
    with_message_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="history",
    )
    return with_message_history

# TTS (OpenAI gpt-4o-mini-tts) : ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (wav ì„ì‹œíŒŒì¼ ë°˜í™˜)
async def generate_tts_wav(text, voice="alloy", instructions=INSTRUCTIONS):
    client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    tmp_pcm = tempfile.NamedTemporaryFile(delete=False, suffix=".pcm")
    tmp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    # 1. PCM ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ë° ì €ì¥
    async with client.audio.speech.with_streaming_response.create(
        model="gpt-4o-mini-tts",
        voice=voice,
        input=text,
        instructions=instructions,
        response_format="pcm",
    ) as response:
        with open(tmp_pcm.name, "wb") as f:
            async for chunk in response.iter_bytes():
                f.write(chunk)
    # 2. PCM â†’ WAV ë³€í™˜ (16kHz, 1ch, 16bit)
    import wave
    with open(tmp_pcm.name, "rb") as pcmfile:
        pcmdata = pcmfile.read()
    with wave.open(tmp_wav.name, "wb") as wavfile:
        wavfile.setnchannels(1)
        wavfile.setsampwidth(2)  # 16bit PCM = 2 bytes
        wavfile.setframerate(24000)  # OpenAI PCMì€ 24kHz
        wavfile.writeframes(pcmdata)
    return tmp_wav.name

# -------------------------------------
# Streamlit ì¸í„°í˜ì´ìŠ¤
# -------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    model_name = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        ["gpt-4.1-nano", "gpt-4.1-mini", "gpt-4o-mini"],
        index=0
    )
    temperature = st.slider(
        "Temperature (ì°½ì˜ì„±)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1
    )
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        get_chat_history().clear()
        st.rerun()

msgs = get_chat_history()

# íˆìŠ¤í† ë¦¬ ì¶œë ¥
for message in msgs.messages:
    with st.chat_message(message.type):
        st.markdown(message.content)

chatbot = create_chatbot(model_name=model_name, temperature=temperature)

# ì…ë ¥ ë°•ìŠ¤ ë° ì²˜ë¦¬
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

if user_input:
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # 1. LLM ë‹µë³€ ìƒì„±
            response = chatbot.invoke(
                {"input": user_input},
                config={"configurable": {"session_id": "default"}}
            )
            # íƒ€ì´í•‘ íš¨ê³¼
            displayed_response = ""
            for word in response.split():
                displayed_response += word + " "
                time.sleep(0.05)
                message_placeholder.markdown(displayed_response + "â–Œ")
            # ìµœì¢… ë‹µë³€
            message_placeholder.markdown(response)

            # 2. OpenAI TTSë¡œ ìŒì„± ë³€í™˜ ë° ì¬ìƒ
            st.info("AI ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë“£ëŠ” ì¤‘...")
            wav_path = asyncio.run(generate_tts_wav(response))
            audio_file = open(wav_path, 'rb')
            audio_bytes = audio_file.read()
            st.audio(audio_bytes, format="audio/wav")
            audio_file.close()
            os.remove(wav_path)
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")
            message_placeholder.markdown("â— ìŒì„± í•©ì„± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ì•ˆë‚´
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <small>
            ì±—ë´‡ì´ ëŒ€ë‹µí•˜ë©´, AIê°€ ì§ì ‘ ìŒì„±ìœ¼ë¡œ ì½ì–´ì¤ë‹ˆë‹¤.<br>
            <b>ìŒì„±ì´ ìë™ ì¬ìƒë˜ì§€ ì•Šìœ¼ë©´, ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ ì¬ìƒì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.</b>
        </small>
    </div>
    """,
    unsafe_allow_html=True
)
