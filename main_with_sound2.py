import os
from dotenv import load_dotenv
load_dotenv()
import streamlit as st
import time
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# TTS ê´€ë ¨ imports
from gtts import gTTS
from pydub import AudioSegment
import random
import base64
import io

# from prompts.prompt import SYSTEM_PROMPT
from prompts.prompt import PROMPT_DICT

# r2-d2 ìŠ¤íƒ€ì¼ ì„í¬íŠ¸
from r2d2 import generate_r2d2_voice

# ì›¹ì‚¬ì´íŠ¸ ì œëª©
st.title("ìŒì„± ì±—ë´‡")

# ë””ë ‰í† ë¦¬ ìƒì„±
@st.cache_data
def create_directories():
    os.makedirs('samples', exist_ok=True)
    os.makedirs('result', exist_ok=True)
    return True

create_directories()

# ë„ˆêµ´ì´ ìŒì„± ìƒì„± í•¨ìˆ˜
@st.cache_data
def generate_nook_voice(text, lang='ko', random_factor=0.35, normal_frame_rate=44100):
    """ë„ˆêµ´ì´ ìŠ¤íƒ€ì¼ ìŒì„± ìƒì„± (íŠ¹ìˆ˜ë¬¸ì/ìˆ«ìëŠ” ì§§ì€ ë¬´ìŒìœ¼ë¡œ ì²˜ë¦¬)"""
    if not text.strip():
        return None

    result_sound = None
    short_silence = AudioSegment.silent(duration=150)  # 0.15ì´ˆ ì§§ì€ ë¬´ìŒ

    for i, letter in enumerate(text):
        if letter == ' ':  # ê³µë°±
            new_sound = AudioSegment.silent(duration=200)  # 0.2ì´ˆ ë¬´ìŒ
        elif not (letter.isalpha() or '\uAC00' <= letter <= '\uD7A3'):  # í•œê¸€ ë˜ëŠ” ì˜ë¬¸ì´ ì•„ë‹ˆë©´ = íŠ¹ìˆ˜ë¬¸ì/ìˆ«ì
            new_sound = short_silence
        else:
            letter_file = f'samples/{letter}.mp3'
            if not os.path.isfile(letter_file):
                try:
                    tts = gTTS(letter, lang=lang)
                    tts.save(letter_file)
                except Exception as e:
                    st.error(f"TTS ìƒì„± ì‹¤íŒ¨: {letter} - {e}")
                    continue
            try:
                letter_sound = AudioSegment.from_mp3(letter_file)
                if len(letter_sound.raw_data) > 10000:
                    raw = letter_sound.raw_data[5000:-5000]
                else:
                    raw = letter_sound.raw_data
                    
                octaves = 2.0 + random.random() * random_factor
                frame_rate = int(letter_sound.frame_rate * (2.0 ** octaves))
                new_sound = letter_sound._spawn(raw, overrides={'frame_rate': frame_rate})
                
            except Exception as e:
                st.error(f"ìŒì„± ì²˜ë¦¬ ì‹¤íŒ¨: {letter} - {e}")
                continue

        if 'new_sound' in locals():
            new_sound = new_sound.set_frame_rate(normal_frame_rate)
            result_sound = new_sound if result_sound is None else result_sound + new_sound

    return result_sound

# ì˜¤ë””ì˜¤ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ HTMLì—ì„œ ì¬ìƒí•  ìˆ˜ ìˆê²Œ í•¨
def audio_to_base64(audio_segment):
    """AudioSegmentë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    buffer = io.BytesIO()
    audio_segment.export(buffer, format="mp3")
    audio_base64 = base64.b64encode(buffer.getvalue()).decode()
    return audio_base64

# Streamlitìš© ì±„íŒ… íˆìŠ¤í† ë¦¬ ì„¤ì •
@st.cache_resource
def get_chat_history():
    return StreamlitChatMessageHistory(key="chat_messages")

def get_session_history(session_id: str):
    return get_chat_history()

# OpenAI ì±—ë´‡ ì„¤ì •
def create_chatbot(model_name="gpt-3.5-turbo", temperature=0.7, voice_style="ì¼ë°˜"):
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
    prompt = ChatPromptTemplate.from_messages([
        ("system", PROMPT_DICT.get(voice_style, PROMPT_DICT["ì¼ë°˜"])),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    
    # ChatOpenAI ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        model=model_name,
        temperature=temperature
    )
    
    # ì²´ì¸ êµ¬ì„±
    chain = prompt | llm | StrOutputParser()
    
    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ ì‹¤í–‰ ê°€ëŠ¥í•œ ì²´ì¸ ìƒì„±
    with_message_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="history",
    )
    
    return with_message_history

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # ëª¨ë¸ ì„ íƒ
    model_name = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        ["gpt-4.1-nano", "gpt-4.1-mini", "gpt-4o-mini"],
        index=0
    )
    
    # Temperature ì„¤ì •
    temperature = st.slider(
        "Temperature (ì°½ì˜ì„±)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1
    )
    
    # ìŒì„± ì„¤ì •
    st.subheader("ğŸ”Š ìŒì„± ì„¤ì •")
    voice_style = st.radio(
        "ìŒì„± ìŠ¤íƒ€ì¼",
        ["ì¼ë°˜", "ë„ˆêµ´", "r2-d2"],
        index=0
    )
    enable_voice = st.checkbox("ìŒì„± ì¬ìƒ", value=True)
    voice_random_factor = st.slider(
        "ìŒì„± ë³€ì¡° ê°•ë„",
        min_value=0.1,
        max_value=0.8,
        value=0.35,
        step=0.05,
        help="ê°’ì´ í´ìˆ˜ë¡ ë” ë‹¤ì–‘í•œ í†¤ìœ¼ë¡œ ë§í•©ë‹ˆë‹¤"
    )
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        get_chat_history().clear()
        st.rerun()
    
    st.markdown("---")
    st.markdown("ğŸ’¡ **ë™ë¬¼ì˜ ìˆ² 'ë„ˆêµ´'ê³¼ ìŠ¤íƒ€ì›Œì¦ˆì˜ 'r2-d2'ì™€ ëŒ€í™”í•´ë³´ì„¸ìš”. **")
    st.markdown("ğŸ”Š **ê·¸ë¦¬ê³  ì§ì ‘ ë“¤ì–´ë³´ì„¸ìš”!**")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
msgs = get_chat_history()

# í™˜ì˜ ë©”ì‹œì§€ (ìµœì´ˆ ì ‘ì† ì‹œ)
if len(msgs.messages) == 0:
    with st.chat_message("assistant"):
        welcome_msg = "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š"
        st.markdown(welcome_msg)

# ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— í‘œì‹œ
for message in msgs.messages:
    with st.chat_message(message.type):
        st.markdown(message.content)

# ì±—ë´‡ ì„¤ì •
chatbot = create_chatbot(
    model_name=model_name, 
    temperature=temperature,
    voice_style=voice_style
    )

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    
    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        try:
            # AI ì‘ë‹µ ìƒì„±
            response = chatbot.invoke(
                {"input": prompt},
                config={"configurable": {"session_id": "default"}}
            )
            
            # íƒ€ì´í•‘ íš¨ê³¼ë¡œ ì‘ë‹µ í‘œì‹œ
            displayed_response = ""
            for word in response.split():
                displayed_response += word + " "
                time.sleep(0.05)
                message_placeholder.markdown(displayed_response + "â–Œ")
            
            # ìµœì¢… ì‘ë‹µ í‘œì‹œ
            message_placeholder.markdown(response)
            
            # ìŒì„± ìƒì„± ë° ì¬ìƒ
            if enable_voice and response.strip():
                with st.spinner(f"{voice_style} ëª©ì†Œë¦¬ ìƒì„± ì¤‘..."):
                    try:
                        if voice_style == "ì¼ë°˜":
                            tts = gTTS(response, lang='ko')
                            tts_fp = io.BytesIO()
                            tts.write_to_fp(tts_fp)
                            tts_fp.seek(0)
                            audio_seg = AudioSegment.from_file(tts_fp, format="mp3")
                        elif voice_style == "ë„ˆêµ´":
                            audio_seg = generate_nook_voice(
                                response, 
                                random_factor=voice_random_factor
                            )
                        else:  # r2-d2
                            base_dir = os.path.dirname(__file__)
                            audio_seg = generate_r2d2_voice(
                                response,
                                base_dir
                            )
                        if audio_seg:
                            audio_base64 = audio_to_base64(audio_seg)
                            audio_html = f"""
                            <audio autoplay>
                                <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                            </audio>
                            """
                            st.markdown(audio_html, unsafe_allow_html=True)
                            st.download_button(
                                label="ğŸ”Š ìŒì„± ë‹¤ìš´ë¡œë“œ",
                                data=base64.b64decode(audio_base64),
                                file_name=f"{voice_style}_voice_{int(time.time())}.mp3",
                                mime="audio/mp3"
                            )
                        else:
                            st.warning("ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                    except Exception as e:
                        st.error(f"ìŒì„± ìƒì„± ì˜¤ë¥˜: {str(e)}")
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            error_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            message_placeholder.markdown(error_response)

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <small>
            ì±—ë´‡ê³¼ ë‹¤ì–‘í•œ ëª©ì†Œë¦¬ë¡œ ëŒ€í™”í•´ë³´ì„¸ìš”!<br>
            ğŸ’¡ ìŒì„±ì´ ìë™ ì¬ìƒë˜ì§€ ì•Šìœ¼ë©´ ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ìë™ì¬ìƒì„ í—ˆìš©í•´ì£¼ì„¸ìš”.
        </small>
    </div>
    """,
    unsafe_allow_html=True
)
